# Realtime Voice Chat

Low-latency realtime audio assistant that combines Moonshine STT, OpenAI-compatible LLM replies, and F5-TTS one-shot cloning for natural voice responses.

## Features
- ğŸ¤ Moonshine STT via FastRTC for responsive speech recognition.
- ğŸ¤– OpenAI-compatible chat responses (supports custom `OPENAI_BASE_URL`).
- ğŸ—£ï¸ F5-TTS one-shot cloning with streaming 200â€¯ms WAV chunks.
- ğŸšï¸ Persona side panel to upload a reference voice and describe conversational style.
- ğŸ” FastRTC â€œsend-receiveâ€ chat interface for live audio conversations.

## Quickstart

### Prerequisites
- Python 3.10+
- Optional: CUDA-capable GPU for best latency
- Recommended: `ffmpeg` for broader audio format support

### Installation

#### Windows (PowerShell)
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
scripts\setup_windows.ps1
```

#### macOS / Linux (bash)
```bash
bash scripts/setup_unix.sh
```

Both scripts create a virtual environment, install dependencies (including Torch, FastRTC, and F5-TTS), and run the unit tests.

### Configure environment
Copy the template and edit values:

```bash
cp .env.example .env
```

Set at minimum:

```
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini        # change if desired
OPENAI_BASE_URL=http://localhost:8000/v1   # optional for local server
```

### Run the app
```bash
python -m src.app
```

Command-line flag `--cpu` forces CPU inference even when CUDA is available:

```bash
python -m src.app --cpu
```

### Using the realtime chat
1. Open the FastRTC UI (terminal prints the URL) and allow microphone access.
2. Visit the side panel at [http://localhost:7862](http://localhost:7862).
3. Upload a 2â€“10â€¯s clean reference voice clip. The assistant will mimic its tone.
4. Describe conversational persona cues (tone, pacing, fillers, etc.) and save.
5. Start speakingâ€”Moonshine STT transcribes, the LLM responds, and F5-TTS streams cloned speech back within ~0.5â€“1.5â€¯s on GPU.

### Latency tips
- Prefer GPUs (`DEVICE=cuda`).
- Reduce LLM `max_tokens` or persona verbosity.
- Increase `CHUNK_MS` for longer but fewer audio chunks.
- Keep voice samples short (under 10â€¯s) and clean.

### Privacy & passphrase check
For sensitive deployments, optionally require the uploaded voice sample to contain a passphrase:
1. Add an environment variable `VOICE_PASSPHRASE="<your phrase>"`.
2. Extend `set_voice_from_path` to run Moonshine STT on the clip and verify the phrase before accepting.
3. Reject uploads that fail the check to prevent unintended cloning.

### Troubleshooting
- **CUDA not detected**: the app falls back to CPU automatically; ensure compatible Torch build is installed.
- **Audio device errors**: close other audio apps or check system permissions.
- **Windows script blocked**: use the `Set-ExecutionPolicy` command above, then rerun the setup script.

## Project structure
```
realtime-voice-chat/
â”œâ”€ README.md
â”œâ”€ pyproject.toml
â”œâ”€ requirements.txt
â”œâ”€ .env.example
â”œâ”€ src/
â”‚  â”œâ”€ app.py
â”‚  â”œâ”€ config.py
â”‚  â”œâ”€ llm_client.py
â”‚  â”œâ”€ persona.py
â”‚  â”œâ”€ stt_wrapper.py
â”‚  â”œâ”€ tts/
â”‚  â”‚  â””â”€ f5_wrapper.py
â”‚  â””â”€ ui/
â”‚     â”œâ”€ __init__.py
â”‚     â””â”€ side_panel.py
â”œâ”€ tests/
â”‚  â”œâ”€ test_persona.py
â”‚  â”œâ”€ test_f5_wrapper.py
â”‚  â””â”€ test_config.py
â””â”€ scripts/
   â”œâ”€ setup_windows.ps1
   â””â”€ setup_unix.sh
```
